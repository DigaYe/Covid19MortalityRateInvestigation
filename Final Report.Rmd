---
output:
  pdf_document:
    number_sections: yes
    fig_caption: yes
    toc: true
    toc_depth: 3
  word_document: default
fontsize: 10.5pt
header-includes:
- \usepackage{fancyhdr}
- \pagestyle{fancy}
- \fancyhead[R]{Group 1}
- \usepackage{float}
bibliography: thebib.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, tidy = TRUE,tidy.opts=list(width.cutoff= 70), fig.pos = "!h")
```

\pagebreak

# Abstract

# Introduction

For the past 5 months, the coronavirus (Covid-19) pandemic has been raging all over the world. According to the World Health Organization, there are more than 9.44 million confirmed cases worldwide, and the total number of death cases is as high as 483,000 (@who2020). Therefore, we are interested in finding the factors that can potentially explain the Covid-19 mortality rate, as well as the degree to which those factors impact the mortality rate. Since the US has a large number of confirmed cases, we would analyze the Covid-19 cases from US from a statistical standpoint in the below report. By fitting and comparing different models, we hope to gain some insights into the causes of mortality rate of this pandemic. 

# Dataset Description 

```{r  include=FALSE, message=FALSE}
# Input Data and library
library(tidyverse)
library("here")
library(formattable)
library(leaps)
alldata <- read.csv(here::here("data","counties.csv"), header=T) 
attach(alldata)
Physician_rate <- Active.Physicians.per.100000.Population.2018..AAMC.
Specialist <- All.Specialties..AAMC.
ElderlyRate <- Pop_Above_65
Poverty <- POVALL_2018
Migration <- INTERNATIONAL_MIG_2018
Nurse <- Total.nurse.practitioners..2019.
Covid19 <- data.frame(Mortality, ElderlyRate, Region, Specialist, population, Physician_rate, Unemployment_rate_2018, Poverty, Migration, Nurse)
```


The first dataset we found was the US Covid-19 data, which recorded the mortality rate under each county (@coviddata). Another machine-readable dataset (@countydata) we have used contains socioeconomic, demographic, health care, education and transit data for each county in the 50 states in US. In total, there are 347 different factors in this dataset, such as the population estimate, migration rate, number of females, number of hospitals. Furthermore, both datasets include a key called Federal Information Processing Standard Publication (FIPS) code, which is a five-digit code uniquely identifying each area. Thus, by joining these two data sets together with Excel, we obtained our combined data called alldata.

# investigation: single model fitting -> significant 

# Model Selection 
In order to find the best fitting model, we performed a automic model selection process by fitting all possible combinations.
```{r}
f <- regsubsets(Mortality~., data=Covid19,nbest=2, nvmax=11)
e <- summary(f)
attach(e)
cbind(which,cp,adjr2)
```

<<<<<<< HEAD
From the result, we noticed that models containing  at least five variables have a fair cp value and as the number of variables increases the $R_{adj}^2$ increases. Then, we consider the following models:
```{r}
model1 <- lm(Mortality~ElderlyRate + Specialist + Migration + factor(Region))
model2 <- lm(Mortality~ElderlyRate + Nurse + Migration + factor(Region))
model3 <- lm(Mortality~ElderlyRate + Specialist + Migration + Unemployment_rate_2018 + factor(Region))
model4 <- lm(Mortality~ElderlyRate + Nurse + Migration + Unemployment_rate_2018 + factor(Region))
model5 <- lm(Mortality~ElderlyRate + Specialist + Migration + Unemployment_rate_2018 + factor(Region) + factor(population))
model6 <- lm(Mortality~ElderlyRate + Specialist + Migration + Unemployment_rate_2018 + Physician_rate +  factor(Region))
model7 <- lm(Mortality~ElderlyRate + Nurse + Migration + Unemployment_rate_2018 + Physician_rate + factor(Region))
model8 <- lm(Mortality~ElderlyRate + Specialist + Migration + Unemployment_rate_2018 + Physician_rate + factor(Region) + factor(population))
model9 <- lm(Mortality~ElderlyRate + Nurse + Migration + Unemployment_rate_2018 + Physician_rate + factor(Region) + factor(population))
model10 <- lm(Mortality~ElderlyRate + Specialist + Nurse + Migration + Unemployment_rate_2018 + Physician_rate + factor(Region) + factor(population))
model11 <- lm(Mortality~ElderlyRate + Specialist + Migration + Unemployment_rate_2018 + Physician_rate + Poverty + factor(Region) + factor(population))
model12 <- lm(Mortality~ElderlyRate + Specialist + Nurse + Migration + Unemployment_rate_2018 + Physician_rate + Poverty + factor(Region) + factor(population))

A <- AIC(model1,model2,model3,model4,model5,model6,model7,model8,model9,model10,model11,model12, k=2)

B <- BIC(model1,model2,model3,model4,model5,model6,model7,model8,model9,model10,model11,model12)

output_table <- data.frame(A, B) 
knitr::kable(output_table)
```

By comparing this result, we notice that model1, model2, model3, and model4 have the lowest AIC and BIC values. Since model1 is included in model3, and model2 is included in model4. First, to compare model1 and model3, we use backward elimination procedure. 

Step 1: start by fitting Model3: Mortality~ElderlyRate + Specialist + Migration + Unemployment_rate_2018 + factor(Region), and consider the partial t tests for each explanatory variable.

```{r}
summary(model3)
```

According to the result, the p-value for Unemployment_rate_2018 = 0.07634 > $\alpha = 0.05$ which means Unemployment_rate_2018 is not statistically significant. Then, we omit the variable Unemployment_rate_2018 from the model.

```{r}
summary(model1)
```

Step 2: Repeat the procedure in step 1 with a simplified model excluding the Unemployment_rate_2018, which is the our model1. The p-value for ElderlyRate = 4.33e-07 < $\alpha = 0.05$,the p-value for Specialist = 0.02241 < $\alpha = 0.05$, p-value for Migration = 0.00516 < $\alpha = 0.05$, and the p-values for most categories under Region are under $\alpha = 0.05$. This suggests that all variables inside this model are statistically significant. Thus we cannot further simplify this model and this model would be one of our best models to consider.

Next, to compare model2 and model4, we use the extra sum of squares principle since model2 is nested within model4. So, we performed a hypothesis test on the variable Unemployment_rate_2018.

```{r}
summary(model2)
summary(model4)
```

Hypothesis test:

(1) $H_0$: $\beta_{unemployment} = 0$ vs. $H_a$: $\beta_{unemployment} \ne 0$

(2) $f_0 = \frac{(1.035 - 1.034)/(1724-1723)}{1.034/1723} = 1.66634$

```{r}
(pval4 <- pf(1.66634,1, 1723, lower.tail = FALSE))
```

(3) p-value = $P(F_{1,1723} > 1.66634) = 0.197$ 

(4) Since p-value > $\alpha = 0.05$, then we do not reject $H_0$ at a 5% level of significance, which suggests the addition variable Unemployment_rate_2018 is not useful.

Thus we choose model2 as one of our best models to consider.

Lastly, we compare model1 and model2 results. We notice model1 and model2 have the same standard error, but model1 has a lower p-value and higher $R_{adj}^2$ compared to model2. Therefore, we select model1: Mortality ~ ElderlyRate + Specialist + Migration + factor(Region) as our final model.

# Assumption Checking (Diga)
=======
# Assumption Checking 

```{r full_model, fig.cap= "\\label{fig:plot_full_model}Plot for Model Checking", fig.height = 10, fig.width = 10}
full_model <- lm(Mortality ~ ElderlyRate + factor(population) + factor(Region))
summary(full_model)
par(mfrow = c(2, 2))
plot(full_model,cex.lab=1.1, cex.axis=1.1, cex.main=1, cex.sub=0.8)
```

## Mean of 0: 

Looking at the plot of Residuals vs. Fitted values the residuals do appear randomly scatter around the value 0. As such, it appears to satisfy the assumption of mean of 0.

## Independence: 

Again the plot of Residuals vs. Fitted values shows the residuals randomly scattered with no apparent trend and thus satisfied.

## Constant Variance: 

The Scale location plot suggests that the majority of residuals are randomly scattered evenly within an upper and lower band around the value 0, which indicates a constant variance. However, since there is a few larger residuals (such as observation 31, 90 and 98) on the top, the red line bulges in the middle of the majority data point, causing a slightly increase and decrease in variability. Thus, it is considered fairly satisfied.

## Normality: 

The Q-Q plot overall appears good, since most of the residuals are lying on a straight line. However, the normality assumption can only be considered as fairly satisfied, since there are some point at the tails are off the line, suggesting some potential outliers. 

## Outliers:

It could be seen that there are some potential outliers, as we could find that there are some points off the straight at the tails in Q-Q plot, which appears to be outliers. 

In terms of the leverage and Standard Residual plot, it could seen that there is a point on the very right side and a few other points slightly upper and lower compared to the rest of majority of observations. As such, those points are considered to have a high leverage, whereas they are all within the Cook's Distance. Thus, these points are considered not to be influential. 
>>>>>>> dd3cf0ad8f0b3922af85115f104e0b2c58e5cdbd

# Results

# Limitation of Study 

# Conclusion 

\pagebreak

# Appendix{-}

# Reference {-}

\pagebreak

# R Code {-}


