---
output:
  pdf_document:
    number_sections: yes
    fig_caption: yes
    toc: true
    toc_depth: 2
  word_document: default
fontsize: 12pt
header-includes:
- \usepackage{fancyhdr}
- \pagestyle{fancy}
- \fancyhead[R]{Group 1}
- \usepackage{float}

bibliography: thebib.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, tidy = TRUE,tidy.opts=list(width.cutoff= 70), fig.pos = "!h")
```

\pagebreak

# Abstract

The purpose of this study is to identify the factors that prominently affect the U.S. COVID-19 mortality rate. We used a dataset comprising various information of 1739 different US counties, which contains the variable of interest- the mortality rate of each county, as well as over 300 potential explanatory variables, including but not limited to information on demographic and healthcare. The question of interest is to identify the most appropriate explanatory variables and to find the most suitable and statistically significant linear model to reflect these variables' effects on the mortality rate. We started by identifying the best 9 explanatory variables that were the most reasonable and statistically significant in their respective single models. Then, using the automatic model selection method, we identified the best 2 models for each model size. Next, by comparing their $R_{adj}^2$, AIC values, BIC values, $C_{p}$ values, and taking multicollinearity into consideration, we selected the final model consisting of 4 explanatory variables, including the percentage of the population above 65 years old in the county, the total number of specialist in the county, the incoming number of International immigrants in the county for the past year, and the large-scale region to which the county belongs, which is a categorical variable of 4 large region bounds. Based on our dataset, the linear model consisting of these 4 variables best represents the trend and variation of the mortality rate. Further studies on the US COVID-19 mortality rate is recommended where more suitable explanatory variables are included in order to increase the explanatory power of the model.


# Introduction

For the past 5 months, the coronavirus (COVID-19) pandemic has been raging all over the world. According to the World Health Organization, there are more than 9.44 million confirmed cases worldwide, and the total number of death cases is as high as 483,000 (@who2020). Therefore, we are interested in finding the factors that can potentially explain the COVID-19 mortality rate, as well as the degree to which those factors impact the mortality rate. Since the U.S. has a large number of confirmed cases (@coviddata), we would use the COVID-19 cases from the U.S. and the corresponding counties' data (@countydata) to analyze the causes of the mortality rate for this pandemic. 

From our previous report, we have found some statistically significant variables to the mortality rate of COVID-19, which are region, percentage of elder population, specialists and physicians. Thus, in this report, we would first extend our investigation to search for reasonable factors that are statistically significant to the COVID-19 mortality rate. Based on all these results, we shall then conduct statistical analysis in comparing and fitting different models. Ultimately, we wish to gain some important insights from the mortality rate of COVID-19 by finding the best statistical significant model. 


# Dataset Description 

```{r  include=FALSE, message=FALSE}
# Input Data and library
library(tidyverse)
library("here")
library(formattable)
library(leaps)
library(car)
library(MPV)
library(leaps)
library(MASS)
library(knitr)
library(kableExtra)
alldata <- read.csv(here::here("data","counties.csv"), header=T) 
attach(alldata)
Physician_rate <- Active.Physicians.per.100000.Population.2018..AAMC.
Specialist <- All.Specialties..AAMC.
ElderlyRate <- Pop_Above_65
Poverty <- POVALL_2018
Migration <- INTERNATIONAL_MIG_2018
Nurse <- Total.nurse.practitioners..2019.
Covid19 <- data.frame(Mortality, ElderlyRate, Region, Specialist, population, Physician_rate, Unemployment_rate_2018, Poverty, Migration, Nurse)
```


The first dataset we found was the U.S. COVID-19 data, which recorded the mortality rate under each county (@coviddata). Another machine-readable dataset (@countydata) we used contains socioeconomic, demographic, health care, education and transit data for each county in the U.S. In total, there are 347 different factors in this dataset, such as the population estimate, migration rate, number of females, number of hospitals. Furthermore, both datasets include a key called Federal Information Processing Standard Publication (FIPS) code, which is a five-digit code that uniquely identifies each county. Thus, by joining these two data sets together in Excel, we obtain our master data. 

Furthermore, we are interested in the mortality rate and has set it to be our response variable. To satisfy the normality assumption, we created a column called Mortality, which is the natural logarithm of mortality rate of each county. As such, we could use Mortality to be our response variable when computing the statistic models. 

# Investigation

In the previous report, we have identified 6 individually significant explanatory variables, including Specialist, Physician_rate, ElderlyRate, Region, Population, Unemployment_rate_2018. Due to the low $R_{adj}^2$ value in those models, we searched in our dataset for additional explanatory variables that reasonably affects the COVID-19 mortality rate. Among the variables that are reasonable to be included, we selected 3 of them whose corresponding single-variable models were tested significant at $\alpha =0.05$ level of significance. These additional variables are Poverty, Migration, and Nurse, making a total of 9 variables selected.

The p-value of the global F-tests for the corresponding 9 single-model fittings are listed below. Full single-model summaries are included in the appendix. 

```{r}
d1=data.frame(Variable= c("ElderlyRate", "Region", "Specialist", "population", "Physician_rate", "Unemployment_rate_2018","Poverty", "Migration","Nurse"), p_value = c(7.072*10^(-7), 0.02471,0.02745, 0.01440, 0.04606, 0.04841, 0.02501, 0.00275, 0.01404))
kable(d1,align = "l",booktabs = T, caption = "P-values for Selected Explanatory Variables",linesep = "")%>%
  kable_styling(position = "center", full_width = FALSE,latex_options = "HOLD_position")%>%
  column_spec(1, width = "20em")
```

As shown above, all 9 of those explanatory variables are statistically significant; we then select the best model based on those 9 variables. Firstly, we will observe the correlation matrix and VIF of those variables to spot red flags for multicollinearity.

```{r}
x<-data.frame(ElderlyRate, Specialist, Physician_rate, Unemployment_rate_2018, Poverty, Migration, Nurse)
cor_matrix <- cor(x)
output_matrix <- round(cor_matrix,3)
kable(output_matrix,align = "l",booktabs = T, caption = "Correlation Matrix",
      col.names = c("Elderly","Specilist","Physician","Unemployment", "Poverty","Migration", "Nurse"))%>%
  kable_styling(position = "center", full_width = TRUE,latex_options = "HOLD_position")%>%
  column_spec(1, width = "12em")%>%
  column_spec(5, width = "6em")%>%
  column_spec(7, width = "5em")%>%
  column_spec(4, width = "4em")

fullmodel<-lm(Mortality ~ ElderlyRate + factor(Region) + Specialist + factor(population) + Physician_rate + Unemployment_rate_2018 + Poverty + Migration + Nurse)

vif_value <- vif(fullmodel)
kable(vif_value,align = "l",booktabs = T, caption = "VIF Values")%>%
  kable_styling(position = "center", full_width = FALSE, latex_options = "HOLD_position")%>%
  column_spec(1, width = "15em")
```



Observe the correlation matrix. Using 0.8 as a cutoff, we see signs of multicollinearity issues in the following pairs of variables: Specialist & Poverty, Specialist & Migration, Specialist & Nurse, Poverty & Migration, Poverty & Nurse, Migration & Nurse. 

Observe the GVIF values. Using the value 5 as a cutoff, we see signs of multicollinearity issues in Specialist, Poverty, Migration, and Nurse. 


# Model Selection 
## Automatic model selection method
To start our model selection process, we used the stepwise selection method first given the full model as the initial model to find the best model based on algorithm.
```{r}
step.model <- stepAIC(fullmodel, direction = "both",  trace = FALSE)
summary(step.model)
step.model$anova
```

The stepwise method gives the model: Mortality ~ ElderlyRate + factor(Region) + Specialist + Physician_rate + Unemployment_rate_2018 + Migration) as the final model. However, we noticed the p-value for Physician_rate = 0.13894 > $\alpha = 0.05$ and the p-value for Unemployment_rate_2018 = 0.09422 > $\alpha = 0.05$, which do not indicate statistical significance. Thus, the model is not the most suitable model for our dataset.

## Model selection process   
In order to find the best fitting model, we performed another model selection process by fitting all possible combinations.


```{r, fig.pos="H"}
f <- regsubsets(Mortality~., data=Covid19,nbest=2, nvmax=11)
e <- summary(f)
attach(e)
explain1 <- data.frame(Num = c("0","1","2","3"), Variable = c("Intercept","ElderlyRate", "RegionNorthEast","RegionSouth"),Num = c("4","5", "6","7"), Variable = c("RegionWest","Specialist", "populationSmall","PhysicianRate"), Num = c("8","9","10","11"), Variable = c("Unemployment_Rate_2018","Poverty","Migration","Nurse"))
kable(explain1,align = "l",booktabs = T, caption = "Variable Reference")%>%
  kable_styling(position = "center", full_width = FALSE,latex_options = "HOLD_position")%>%
  column_spec(1, width = "5em")
```


```{r CpValue}
combination <- cbind(which,cp,adjr2)
kable(combination,align = "l",booktabs = T, caption = "Model Selection with CP values",
      col.names = c("0", "1","2","3","4","5","6","7","8","9","10","11", "cp","adjr2"))%>%
  kable_styling(position = "center", full_width = FALSE, latex_options = "HOLD_position")%>%
  column_spec(1, width = "5em")
```


From the result, we noticed that models containing  at least five variables have a fair Cp value and as the number of variables increases the $R_{adj}^2$ increases. Then, we consider the following models:

```{r}
model1 <- lm(Mortality~ElderlyRate + Specialist + Migration + factor(Region))
model2 <- lm(Mortality~ElderlyRate + Nurse + Migration + factor(Region))
model3 <- lm(Mortality~ElderlyRate + Specialist + Migration + Unemployment_rate_2018 + factor(Region))
model4 <- lm(Mortality~ElderlyRate + Nurse + Migration + Unemployment_rate_2018 + factor(Region))
model5 <- lm(Mortality~ElderlyRate + Specialist + Migration + Unemployment_rate_2018 + factor(Region) + factor(population))
model6 <- lm(Mortality~ElderlyRate + Specialist + Migration + Unemployment_rate_2018 + Physician_rate +  factor(Region))
model7 <- lm(Mortality~ElderlyRate + Nurse + Migration + Unemployment_rate_2018 + Physician_rate + factor(Region))
model8 <- lm(Mortality~ElderlyRate + Specialist + Migration + Unemployment_rate_2018 + Physician_rate + factor(Region) + factor(population))
model9 <- lm(Mortality~ElderlyRate + Nurse + Migration + Unemployment_rate_2018 + Physician_rate + factor(Region) + factor(population))
model10 <- lm(Mortality~ElderlyRate + Specialist + Nurse + Migration + Unemployment_rate_2018 + Physician_rate + factor(Region) + factor(population))
model11 <- lm(Mortality~ElderlyRate + Specialist + Migration + Unemployment_rate_2018 + Physician_rate + Poverty + factor(Region) + factor(population))
model12 <- lm(Mortality~ElderlyRate + Specialist + Nurse + Migration + Unemployment_rate_2018 + Physician_rate + Poverty + factor(Region) + factor(population))

A <- AIC(model1,model2,model3,model4,model5,model6,model7,model8,model9,model10,model11,model12, k=2)

B <- BIC(model1,model2,model3,model4,model5,model6,model7,model8,model9,model10,model11,model12)

d2=data.frame(Model= c(1, 2, 3, 4, 5, 6,7, 8,9,10,11,12), Regression_Equation = c("Log of Mortality Rate vs. ElderlyRate + Specialist + Migration + Region","Log of Mortality Rate vs. ElderlyRate + Nurse + Migration + Region", "Log of Mortality Rate vs. ElderlyRate + Specialist + Migration + Unemployment_rate_2018 + Region","Log of Mortality Rate vs. ElderlyRate + Nurse + Migration + Unemployment_rate_2018 + Region","Log of Mortality Rate vs. ElderlyRate + Specialist + Migration + Unemployment_rate_2018 + Region + population","Log of Mortality Rate vs. ElderlyRate + Specialist + Migration + Unemployment_rate_2018 + Physician_rate +  Region","Log of Mortality Rate vs. ElderlyRate + Nurse + Migration + Unemployment_rate_2018 + Physician_rate + Region","Log of Mortality Rate vs. ElderlyRate + Specialist + Migration + Unemployment_rate_2018 + Physician_rate + Region + population","Log of Mortality Rate vs. ElderlyRate + Nurse + Migration + Unemployment_rate_2018 + Physician_rate + Region + population","Log of Mortality Rate vs. ElderlyRate + Specialist + Nurse + Migration + Unemployment_rate_2018 + Physician_rate + Region + population","Log of Mortality Rate vs. ElderlyRate + Specialist + Migration + Unemployment_rate_2018 + Physician_rate + Poverty + Region + population","Log of Mortality Rate vs. ElderlyRate + Specialist + Nurse + Migration + Unemployment_rate_2018 + Physician_rate + Poverty + Region + population"))
```

```{r, fig.pos="H"}
kable(d2,align = "cl",booktabs = T, caption = "Automatic Selection Model Summary")%>%
  kable_styling(position = "center", full_width = TRUE,latex_options = "HOLD_position")%>%
  column_spec(1, width = "5em")%>%
  row_spec(1:12, hline_after = TRUE)

```


```{r AIC&BIC}
output_table <- data.frame(A, B[2]) 
kable(output_table,align = "l",booktabs = T, caption = "AIC and BIC values")%>%
  kable_styling(position = "center", full_width = FALSE,latex_options = "HOLD_position")%>%
  column_spec(1, width = "5em")
```



By comparing this result, we notice that model1, model2, model3, and model4 have the lowest AIC and BIC values. Since model1 is included in model3, and model2 is included in model4. First, to compare model1 and model3, we use backward elimination procedure. 

Step 1: start by fitting Model3: Mortality~ElderlyRate + Specialist + Migration + Unemployment_rate_2018 + factor(Region), and consider the partial t tests for each explanatory variable.

```{r}
summary(model3)
```

According to the result, the p-value for Unemployment_rate_2018 = 0.07634 > $\alpha = 0.05$ which means Unemployment_rate_2018 is not statistically significant. Then, we omit the variable Unemployment_rate_2018 from the model.

```{r}
summary(model1)
```

Step 2: Repeat the procedure in step 1 with a simplified model excluding the Unemployment_rate_2018, which is the our model1. The p-value for ElderlyRate = 4.33e-07 < $\alpha = 0.05$,the p-value for Specialist = 0.02241 < $\alpha = 0.05$, p-value for Migration = 0.00516 < $\alpha = 0.05$, and the p-values for most categories under Region are under $\alpha = 0.05$. This suggests that all variables inside this model are statistically significant. Thus we cannot further simplify this model and this model would be one of our best models to consider.

Next, to compare model2 and model4, we use the extra sum of squares principle since model2 is nested within model4. So, we performed a hypothesis test on the variable Unemployment_rate_2018.

```{r}
summary(model2)
summary(model4)
```

Hypothesis test:

(1) $H_0$: $\beta_{unemployment} = 0$ vs. $H_a$: $\beta_{unemployment} \ne 0$

(2) $f_0 = \frac{(1.035 - 1.034)/(1724-1723)}{1.034/1723} = 1.66634$

```{r}
(pval4 <- pf(1.66634,1, 1723, lower.tail = FALSE))
```

(3) p-value = $P(F_{1,1723} > 1.66634) = 0.197$ 

(4) Since p-value > $\alpha = 0.05$, then we do not reject $H_0$ at a 5% level of significance, which suggests the addition variable Unemployment_rate_2018 is not useful.

Thus we choose model2 as one of our best models to consider.

Then, we compare model1 and model2 results. We notice model1 and model2 have the same standard error, but model1 has a lower p-value and higher $R_{adj}^2$ compared to model2. Thus, we choose model1 to further investigate on. Moreover, we want to investigate on the collinearity of these two variables.

```{r model_int}
model_int <- lm(Mortality~ElderlyRate + Specialist + Migration + factor(Region) + Specialist * Migration)
summary(model_int)
anova(model_int)
```

The overall p-value = 1.548e-07 < $\alpha = 0.05$, which is higher that the model1. The adjusted $R^2$ = 0.02163 which is lower than 0.0218 from model1, which means the model that includes the interaction term explains less variability. Besides, the p-values for Migration increases to 0.2797 > $\alpha = 0.05$ which do not indicate statistically significant. Besides, the global F-statistic = 6.463 which is lower than 7.425 from model1. Thus, adding the interaction term does not contribute to our study, and we decide to stay with model1. 

We notice from previous analysis that Specialist and Migration have a correlation of 0.855, which shows they are highly correlated. Also, Specialist has a VIF value more than 50, and Migration has a VIF value of 5 indicating multicollinearity issue between these two variables. However, for the current dataset, we choose to stay with model1 as our best model, and will need to investigate on this using a larger dataset.

Based on the method we used and models we discussed, we select model1: Mortality ~ ElderlyRate + Specialist + Migration + factor(Region) as the most suitable model for the given COVID-19 dataset.


# Assumption Checking 

```{r Plotmodel1, fig.cap= "\\label{fig:plot_full_model}Plot for Model Checking", fig.height = 10, fig.width = 10}
par(mfrow = c(2, 2))
plot(model1,cex.lab=1.1, cex.axis=1.1, cex.main=1, cex.sub=0.8)
```

## Mean of 0: 

Looking at the plot of Residuals vs. Fitted values the residuals do appear randomly scatter around the value 0, whereas there are some points are far away (such as observation 99, 898 & 1114) from the majority which results the mean scatter around 0. However, overall it appears to fairly satisfy the assumption of mean of 0.

## Independence: 

Again the plot of Residuals vs. Fitted values shows the residuals randomly scattered with no apparent trend and thus satisfied.

## Constant Variance: 

The scale location plot suggests that the majority of residuals are randomly scattered within an upper and lower band around the value 0, which suggests a constant variance. However, since there is a few larger residuals at the bottom and on the left hand side, the red line bulges up and down in the middle of the plot, causing a slightly increase and decrease in variability. However, in general, it is still considered fairly satisfied.

## Normality: 

The Q-Q plot overall appears good, since most of the residuals are lying on a straight line. However, the normality assumption can only be considered as fairly satisfied, since there are some points at the tails are off the line (such as observation 99, 898 & 1549), suggesting some potential outliers. 

## Outliers:

It could be seen that there are some potential outliers, as we could find that there are some points off the straight at the tails in Q-Q plot, which appears to be outliers. 

In terms of the leverage and Standard Residual plot, it could seen that there is a point on the very right side and a few other points are far away compared to the rest of majority of observations (observations that are greater than the leverage 0.1). As such, those points are considered to have a high leverage, whereas they are all within the Cook's Distance. Thus, these points are considered not to be influential. 

# Results

We found that Elderly rate, number of Specialists, number of International migrations, and Region are four variables that have major impacts on COVID-19 mortality rate given the dataset. This result matches with our initial speculation. Based on above discussion, the final model is selected to be Mortality ~ ElderlyRate + Specialist + Migration + factor(Region) as it has high $R^2_{adj}$ compared to other models and is overall statistically significant. Besides, the hypothesis tests for individual variables indicate statistical significance. Furthermore, the best linear model fitting for these variables is $Mortality = -3.700e+00 + (2.699e+00)x_{ElderlyRate} + (3.641e-05)x_{Specialist} - (2.297e-05 )x_{Migration} - (8.959e-02)x_{Northeast} - (1.422e-01)x{South} - (2.641e-01)x_{West}$. However, there can several limitations of this study and will be discussed below. 

# Limitation and Conclusion

Even though we have considered model 1:  Mortality ~ ElderlyRate + Specialist + Migration + factor(Region) as our best model, there is still a great degree of limitation from using this model to analyze the mortality rate of COVID-19. First, model 1 has a low explanatory power. Specially, $R^2_{adj}$ = 0.0218, which means model 1 could only explain 2.18% percentage of variability of the mortality rate of COVID-19. This indicates that there is a large room for model improvement. Thus, a further investigation on factors are desired. 

Secondly, multicollinearity issue is presented, which not only undermines the statistical significance of an independent variable, but also violates our model independence assumption. For instance, the correlation between Specialist & Migration is as high as 0.855, highlighting a strong positive linear association in this pair variable. In addition, a very high VIF value (50.404208) of Specialist, suggesting that the association will affect the standard errors. Since the multicollinearity issue is considered very severe in this case, we would need to do further investigation and study about the cause of this issue. The solution for this problem varies by situation. If it is structural multicollinearity, centering the variables could be helpful. (@multi). Another potential solution could be linearly combining the independent variables together into higher power variables. Any of these solutions discussed above would require further study, since they can be difficult and time-consuming to implement. 

In conclusion, the selected model consists of 4 explanatory variables: ElderlyRate, Specialist, Migration, Region, all of which have statistically significant effect on Morality. This model does the best job at representing the US mortality rate of COVID-19 at this stage of the study.

\pagebreak

# Appendix{-}
Below lists the 9 single-model summaries for the selected explanatory variables. 
```{r}
modela <- lm(Mortality~ ElderlyRate)
modelb <- lm(Mortality~ Region)
modelc <- lm(Mortality~ Specialist)
modeld <- lm(Mortality~ population)
modele <- lm(Mortality~ Physician_rate)
modelf <- lm(Mortality~ Unemployment_rate_2018)
modelg <- lm(Mortality~ Poverty)
modelh <- lm(Mortality~ Migration)
modeli <- lm(Mortality~ Nurse)

summary(modela)
summary(modelb)
summary(modelc)
summary(modeld)
summary(modele)
summary(modelf)
summary(modelg)
summary(modelh)
summary(modeli)
```

\pagebreak

# R Code {-}

\pagebreak

# Reference {-}

